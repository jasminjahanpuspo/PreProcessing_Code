{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "mount_file_id": "1sLo1Fh9IkqQ7OBHzHLqicfi1Iu-D7G4D",
      "authorship_tag": "ABX9TyOzBtd9IMOG7PaZCqD/14JV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/puspo1997/PreProcessing_Code/blob/master/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH2fqDNbJ-Pr",
        "outputId": "a7579090-2c6d-42f3-f99c-4940ab7b44f7"
      },
      "source": [
        "!pip install keras==2.1.5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl (334kB)\n",
            "\r\u001b[K     |█                               | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 22.7MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 12.3MB/s eta 0:00:01\r\u001b[K     |████                            | 40kB 11.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 51kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 61kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 71kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 92kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 102kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 112kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 122kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 133kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 143kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 153kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 163kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 174kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 184kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 194kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 204kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 215kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 225kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 235kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 245kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 256kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 266kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 276kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 286kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 296kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 307kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 317kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 327kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 337kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (3.13)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDfJW1E5KBZf",
        "outputId": "73f15c1c-6480-4fc8-994f-89a7e661dbaa"
      },
      "source": [
        "!pip install tensorflow==1.14.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/28/96efba1a516cdacc2e2d6d081f699c001d414cc8ca3250e6d59ae657eb2b/tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3MB 87kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 28.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.19.5)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (54.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
            "Installing collected packages: tensorflow-estimator, keras-applications, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3YweWp2KBc9",
        "outputId": "2c893dd5-37e3-4f47-8088-71adc6e9f523"
      },
      "source": [
        "cd '/content/drive/MyDrive/Mammographic'"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Mammographic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8nCVl1lLW42",
        "outputId": "4641dd68-e595-4ccd-e1a8-aa3c243d3cd2"
      },
      "source": [
        "!git clone https://github.com/DavidReveloLuna/MaskRCNN_Video.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'MaskRCNN_Video' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFdFP5Q7KBfp"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.draw\n",
        "import matplotlib.image\n",
        "import glob\n",
        "import scipy.misc\n",
        "from PIL import Image\n",
        "#import imgaug \n",
        "from imgaug import augmenters as iaa\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XemznmFPKMsK",
        "outputId": "b6bf4ad5-14e4-46a2-81fd-97030bf151ff"
      },
      "source": [
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "ROOT_DIR = ROOT_DIR+\"/Mask_r_cnn\"\n",
        "\n",
        "MAMOGRAM_IMAGE_DIR = \"/scans/pseudo_color_image/\" #Path of the mammograms\n",
        "MAMOGRAM_MASK_DIR = \"/scans/preprocessed_mask/\"# Path of the ground truth masks\n",
        "\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR) # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import model as modellib, utils\n",
        "\n",
        "# Path to trained weights file\n",
        "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_balloon.h5\")\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = os.path.join(\"/content/drive/MyDrive/Mammographic\", \"logs\")#Log directory for saving the weights\n",
        "DEMO_SAVE_DIR = \"/scans/seg_mask/\"# path to save the segmentation masks\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwHFrfmIKSV6"
      },
      "source": [
        "############################################################\n",
        "#  Configurations\n",
        "############################################################\n",
        "\n",
        "\n",
        "class MamogramConfig(Config):\n",
        "    \"\"\"Configuration for training on the toy  dataset.\n",
        "    Derives from the base Config class and overrides some values.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"mamogram\"\n",
        "\n",
        "    # We use a GPU with 12GB memory, which can fit two images.\n",
        "    # Adjust down if you use a smaller GPU.\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1  # Background + lesion\n",
        "\n",
        "    # Number of training steps per epoch,set to the number of training data here\n",
        "    STEPS_PER_EPOCH = 100\n",
        "\n",
        "    # Number of validation steps after each round of training\n",
        "    VALIDATION_STEPS = 10\n",
        "    # Resize mode: \"none\" or \"square\"\n",
        "\n",
        "    IMAGE_RESIZE_MODE = \"square\"\n",
        "    IMAGE_MIN_DIM = 1024\n",
        "    IMAGE_MAX_DIM = 1024\n",
        "\n",
        "    # Skip detections with < DETECTION_MIN_CONFIDENCE\n",
        "    DETECTION_MIN_CONFIDENCE = 0.965 # alter this during testing to generate different TPR at different FPI\n",
        "    # 0.7 0.75 0.8 0.85 0.9"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVXJ7BV7KSZC"
      },
      "source": [
        "############################################################\n",
        "#  Dataset\n",
        "############################################################\n",
        "\n",
        "class MamogramDataset(utils.Dataset):\n",
        "\n",
        "    def load_mamogram(self, subset):\n",
        "        \"\"\"This method loads the actual image\n",
        "        subset is either \"train\" or \"val\" depending on whether the image is part of the training or validation datasets \n",
        "        \"\"\"\n",
        "        # Add classes. We have only one class to add.\n",
        "        # These are the things that will be segmented\n",
        "        self.add_class(\"mamogram\", 1, \"lesion\")\n",
        "\n",
        "        # Train or validation dataset?\n",
        "\n",
        "        #list all the files in the directory with the mamogram images\n",
        "        files = os.listdir(ROOT_DIR + MAMOGRAM_IMAGE_DIR + subset + \"/\")\n",
        "        \n",
        "        for fname in files:            \n",
        "            self.add_image(\"mamogram\", image_id=fname, \n",
        "                           path=ROOT_DIR + MAMOGRAM_IMAGE_DIR + subset +\"/\"+ fname, subset=subset, fname=fname)\n",
        "\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"load the instance masks for an image.\n",
        "        Returns:\n",
        "        a tuple containing:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "        one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        use dtype=np.int32\n",
        "        \"\"\"\n",
        "        image_info = self.image_info[image_id]\n",
        "        info = self.image_info[image_id]\n",
        "        fname = info['fname']\n",
        "        #count=len(fname)\n",
        "       \n",
        "\n",
        "        #files = glob.glob(ROOT_DIR + MAMOGRAM_MASK_DIR + info['subset']+\"/\" + fname[0:-4] + \"*\")\n",
        "        #files=ROOT_DIR + MAMOGRAM_MASK_DIR + \"train\" +\"/\"+ fname\n",
        "        files = glob.glob(ROOT_DIR + MAMOGRAM_MASK_DIR + info['subset']+\"/\" + fname[0:-4] + \"*\")\n",
        "        #print(files)\n",
        "        \n",
        "\n",
        "        masks = []\n",
        "        for i in range(0, len(files)):\n",
        "            #print(i)\n",
        "            data = skimage.io.imread(files[i])\n",
        "            \n",
        "            if data.ndim != 1:\n",
        "                data = skimage.color.rgb2gray(data)\n",
        "          \n",
        "            singleMask = data\n",
        "            if i == 0:\n",
        "                masks = np.zeros((singleMask.shape[0], singleMask.shape[1], len(files)))\n",
        "            masks[:,:,i] = singleMask\n",
        "            #masks=np.array(masks)\n",
        "\n",
        "        instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32))\n",
        "        #instanceMaskMap = [masks.shape[-1]]\n",
        "        \n",
        "        return (masks.astype(np.bool), instanceMaskMap)\n",
        "\n",
        "\n",
        "        #class_ids = np.array([self.class_names.index(s[0]) for s in fname])\n",
        "        #return mask.astype(np.bool), class_ids.astype(np.int32)\n",
        "         #this is VERY important: array of class ids in the order that they appear in bigdata\n",
        "        # Return mask, and array of class IDs of each instance. Since we have\n",
        "        # one class ID only, we return an array of 1\n",
        "\n",
        "    def load_image(self, image_id):\n",
        "        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
        "\t\tTaken from utils.py, any refinements we need can be done here\n",
        "        \"\"\"\n",
        "        # Load image\n",
        "        image = skimage.io.imread(self.image_info[image_id]['path'])\n",
        "        # If grayscale. Convert to RGB for consistency.\n",
        "        if image.ndim != 3:\n",
        "            image = skimage.color.gray2rgb(image)\n",
        "        # If has an alpha channel, remove it for consistency\n",
        "        if image.shape[-1] == 4:\n",
        "            image = image[..., :3]\n",
        "        return image\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        return info[\"path\"]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6LHNTgOKSb4"
      },
      "source": [
        "def train(model):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    # Training dataset.\n",
        "    dataset_train = MamogramDataset()\n",
        "    dataset_train.load_mamogram(\"train\")\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    # Validation dataset\n",
        "    dataset_val = MamogramDataset()\n",
        "    dataset_val.load_mamogram(\"val\")\n",
        "    dataset_val.prepare()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Image augmentation\n",
        "    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n",
        "    aug = iaa.Sequential([\n",
        "        iaa.OneOf([iaa.Fliplr(0.5),\n",
        "                   iaa.Flipud(0.5),\n",
        "                   iaa.Affine(rotate=90),\n",
        "                   iaa.Affine(rotate=180),\n",
        "                   iaa.Affine(rotate=270)]),\n",
        "    ])\n",
        "\n",
        "    # *** This training schedule is an example. Update to your needs ***\n",
        "    # Since we're using a very small dataset, and starting from\n",
        "    # COCO trained weights, we don't need to train too long. Also,\n",
        "    # no need to train all layers, just the heads should do it.\n",
        "    print(\"Training network heads\")\n",
        "\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=10,augmentation=aug,\n",
        "                layers='heads')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJZgpowKKSet"
      },
      "source": [
        "def segment(model, imPath):\n",
        "    \n",
        "    image = skimage.io.imread(imPath)\n",
        "\n",
        "    fname = imPath.split('/')[-1]\n",
        "    mrcnnData = model.detect([image], verbose=1)\n",
        "       # documentation for model.detect:\n",
        "       # \"\"\"Runs the detection pipeline.\n",
        "\n",
        "       # images: List of images, potentially of different sizes.\n",
        "\n",
        "       # Returns a list of dicts, one dict per image. The dict contains:\n",
        "       # rois: [N, (y1, x1, y2, x2)] detection bounding boxes\n",
        "       # class_ids: [N] int class IDs\n",
        "       # scores: [N] float probability scores for the class IDs\n",
        "       # masks: [H, W, N] instance binary masks\n",
        "       # \"\"\"\n",
        "\n",
        "    mrcnnData = mrcnnData[0] #model.detect takes a list of images, but here we only provide one image so the output is a list with just one element\n",
        "\n",
        "    masks = mrcnnData['masks']\n",
        "    for i in range(0, masks.shape[2]):\n",
        "        #iterate through the masks\n",
        "        maskSingle = np.squeeze(masks[:, :, i])\n",
        "        file_name = DEMO_SAVE_DIR + \"demo_mask_\" + str(i) + \"_\" + fname + \"_{:%Y%m%dT%H%M%S}.png\".format(datetime.datetime.now())\n",
        "        \n",
        "\n",
        "        scipy.misc.imsave(file_name, maskSingle.astype(np.int64)) \n",
        "\n",
        "\n",
        "    print(mrcnnData)\n",
        "    print(\"&&&&&&&&&&&: \"+str(mrcnnData['rois']))\n",
        "    print(\"&&&&&&&&&&&: \"+str(mrcnnData['class_ids']))\n",
        "    print(\"&&&&&&&&&&&: \"+str(mrcnnData['scores']))\n",
        "\n",
        "    return\n",
        "\n",
        "def segmentWrapper(model, directory):\n",
        "    \"\"\"wrapper function for segment to take many images as an input, calls segment() on everything in the directory\"\"\"\n",
        "    files = os.listdir(directory)\n",
        "    for f in files:\n",
        "        segment(model, directory + '/' + f)\n",
        "\n",
        "\n",
        "\n",
        "def overlayResult(image, mask):\n",
        "\t\"\"\"Function to overlay segmentation mask on an image.\n",
        "\tusage: image_var = overlayResult(image, dict['masks'] || masks_var)\n",
        "\t\n",
        "\timage: RGB or grayscale image [height, width, 1 || 3].\n",
        "\tmask: segmentation mask [height, width, instance_count]\n",
        "\t\n",
        "\treturns resulting image.\n",
        "\t\"\"\"\n",
        "\t# Image is already in grayscale so we skip converting it\n",
        "\t# May need to create 3 dimensions if single dimension image though so\n",
        "\t# will add this as a placeholder\n",
        "\tgray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n",
        "\t# Copy color pixels from the original color image where mask is set\n",
        "\tif mask.shape[-1] > 0:\n",
        "\t\t#collapse masks into one layer\n",
        "\t\tmask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
        "\t\toverlay = np.where(mask, image, gray).astype(np.uint8)\n",
        "\telse:\n",
        "\t\toverlay = gray.astype(np.uint8)\n",
        "\t\t\n",
        "\treturn overlay\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezOa5V9bKwF8",
        "outputId": "402c73d5-b969-4a5a-9c74-8722df9d0132"
      },
      "source": [
        "config = MamogramConfig()\n",
        "#config.display()\n",
        "\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                                  model_dir=DEFAULT_LOGS_DIR)\n",
        "\n",
        "weights_path = COCO_WEIGHTS_PATH\n",
        "\n",
        "\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "train(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3655: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1940: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Training network heads\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /content/drive/MyDrive/Mammographic/logs/mamogram20210326T1539/mask_rcnn_mamogram_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:774: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:777: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/10\n",
            " 49/100 [=============>................] - ETA: 45:01 - loss: 169.9252 - rpn_class_loss: 3.1636 - rpn_bbox_loss: 166.7616 - mrcnn_class_loss: 6.0821e-08 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}